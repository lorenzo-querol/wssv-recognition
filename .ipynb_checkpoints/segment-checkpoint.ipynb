{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2698ae4c-7c3c-4201-a290-57d958bda2c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import pathlib\n",
    "import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3827fab9-e5ca-41c4-90b9-5a665b136bbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "155"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_DIR = \"dataset\"\n",
    "DATA_DIR = list(glob.glob(f\"{DATA_DIR}/*/*.jpg\"))\n",
    "len(DATA_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f5e8a1dd-e3e4-44ab-b282-c673612c05aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def preprocess_image(image):\n",
    "    \"\"\"Reshape the image to a 2D array of pixels and 3 color values (RGB) and convert to float.\"\"\"\n",
    "    pixel_values = image.reshape((-1, 3))\n",
    "    return np.float32(pixel_values)\n",
    "\n",
    "def perform_kmeans_clustering(pixel_values, k=3):\n",
    "    \"\"\"Perform k-means clustering on the pixel values.\"\"\"\n",
    "    criteria = (cv.TERM_CRITERIA_EPS + cv.TERM_CRITERIA_MAX_ITER, 100, 0.2)\n",
    "    compactness, labels, centers = cv.kmeans(pixel_values, k, None, criteria, 10, cv.KMEANS_RANDOM_CENTERS)\n",
    "    return compactness, labels, np.uint8(centers)\n",
    "\n",
    "def create_segmented_image(pixel_values, labels, centers):\n",
    "    \"\"\"Create a segmented image using the cluster centroids.\"\"\"\n",
    "    segmented_image = centers[labels.flatten()]\n",
    "    return segmented_image.reshape(image.shape)\n",
    "\n",
    "def create_masked_image(image, labels, cluster_to_disable):\n",
    "    \"\"\"Create a masked image by disabling a specific cluster.\"\"\"\n",
    "    masked_image = np.copy(image).reshape((-1, 3))\n",
    "    masked_image[labels.flatten() == cluster_to_disable] = [0, 0, 0]\n",
    "    return masked_image.reshape(image.shape)\n",
    "\n",
    "def clean_mask(image):\n",
    "    kernel = np.ones((3,3), np.uint8)\n",
    "    closing = cv.morphologyEx(image, cv.MORPH_CLOSE, kernel, iterations=3)\n",
    "    return closing\n",
    "\n",
    "def display_image(image):\n",
    "    \"\"\"Display the image using matplotlib.\"\"\"\n",
    "    plt.imshow(image)\n",
    "    plt.axis('off')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "3de81142-5fcd-40cd-9a04-a661269659c1",
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.7.0) /io/opencv/modules/imgproc/src/color.simd_helpers.hpp:92: error: (-2:Unspecified error) in function 'cv::impl::{anonymous}::CvtHelper<VScn, VDcn, VDepth, sizePolicy>::CvtHelper(cv::InputArray, cv::OutputArray, int) [with VScn = cv::impl::{anonymous}::Set<3, 4>; VDcn = cv::impl::{anonymous}::Set<1>; VDepth = cv::impl::{anonymous}::Set<0, 2, 5>; cv::impl::{anonymous}::SizePolicy sizePolicy = cv::impl::<unnamed>::NONE; cv::InputArray = const cv::_InputArray&; cv::OutputArray = const cv::_OutputArray&]'\n> Invalid number of channels in input image:\n>     'VScn::contains(scn)'\n> where\n>     'scn' is 1\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[104], line 91\u001b[0m\n\u001b[1;32m     89\u001b[0m image \u001b[38;5;241m=\u001b[39m read_image(path)\n\u001b[1;32m     90\u001b[0m mask \u001b[38;5;241m=\u001b[39m kmeans_segmentation(image)\n\u001b[0;32m---> 91\u001b[0m mask \u001b[38;5;241m=\u001b[39m \u001b[43mspot_cleanup\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     92\u001b[0m masked_image \u001b[38;5;241m=\u001b[39m cv\u001b[38;5;241m.\u001b[39mbitwise_and(image, image, mask\u001b[38;5;241m=\u001b[39mmask)\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28mprint\u001b[39m(masked_image\u001b[38;5;241m.\u001b[39mshape)\n",
      "Cell \u001b[0;32mIn[104], line 64\u001b[0m, in \u001b[0;36mspot_cleanup\u001b[0;34m(image)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mspot_cleanup\u001b[39m(image):\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;66;03m# Convert the image to grayscale\u001b[39;00m\n\u001b[0;32m---> 64\u001b[0m     gray \u001b[38;5;241m=\u001b[39m \u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcvtColor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCOLOR_BGR2GRAY\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;66;03m# Perform adaptive thresholding to obtain a binary image\u001b[39;00m\n\u001b[1;32m     67\u001b[0m     _, binary \u001b[38;5;241m=\u001b[39m cv\u001b[38;5;241m.\u001b[39mthreshold(gray, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m255\u001b[39m, cv\u001b[38;5;241m.\u001b[39mTHRESH_BINARY_INV \u001b[38;5;241m+\u001b[39m cv\u001b[38;5;241m.\u001b[39mTHRESH_OTSU)\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.7.0) /io/opencv/modules/imgproc/src/color.simd_helpers.hpp:92: error: (-2:Unspecified error) in function 'cv::impl::{anonymous}::CvtHelper<VScn, VDcn, VDepth, sizePolicy>::CvtHelper(cv::InputArray, cv::OutputArray, int) [with VScn = cv::impl::{anonymous}::Set<3, 4>; VDcn = cv::impl::{anonymous}::Set<1>; VDepth = cv::impl::{anonymous}::Set<0, 2, 5>; cv::impl::{anonymous}::SizePolicy sizePolicy = cv::impl::<unnamed>::NONE; cv::InputArray = const cv::_InputArray&; cv::OutputArray = const cv::_OutputArray&]'\n> Invalid number of channels in input image:\n>     'VScn::contains(scn)'\n> where\n>     'scn' is 1\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "grid = 5\n",
    "i = 0\n",
    "\n",
    "def shrimp_segmentation(image):\n",
    "    # Convert the image to the HSV color space\n",
    "    hsv = cv.cvtColor(image, cv.COLOR_BGR2HSV)\n",
    "\n",
    "    # Define the lower and upper threshold values for shrimp color\n",
    "    lower_threshold = np.array([0, 20, 20])  # Adjust these values based on the shrimp color\n",
    "    upper_threshold = np.array([20, 255, 255])  # Adjust these values based on the shrimp color\n",
    "\n",
    "    # Create a mask based on the color threshold\n",
    "    mask = cv.inRange(hsv, lower_threshold, upper_threshold)\n",
    "\n",
    "    # Perform morphological operations to enhance the mask\n",
    "    kernel = cv.getStructuringElement(cv.MORPH_ELLIPSE, (5, 5))\n",
    "    mask = cv.morphologyEx(mask, cv.MORPH_OPEN, kernel, iterations=2)\n",
    "    mask = cv.morphologyEx(mask, cv.MORPH_CLOSE, kernel, iterations=2)\n",
    "\n",
    "    # Apply the mask to the original image\n",
    "    segmented_image = cv.bitwise_and(image, image, mask=mask)\n",
    "\n",
    "    return segmented_image\n",
    "\n",
    "def read_image(file_path):\n",
    "    \"\"\"Read the image and convert it to RGB.\"\"\"\n",
    "    image = cv.imread(file_path)\n",
    "    return cv.cvtColor(image, cv.COLOR_BGR2RGB)\n",
    "\n",
    "\n",
    "def kmeans_segmentation(image):\n",
    "    # Reshape the image to a 2D array of pixels\n",
    "    pixels = image.reshape(-1, 3).astype(np.float32)\n",
    "\n",
    "    # Define the criteria and perform k-means clustering\n",
    "    criteria = (cv.TERM_CRITERIA_EPS + cv.TERM_CRITERIA_MAX_ITER, 10, 1.0)\n",
    "    _, labels, centers = cv.kmeans(pixels, 2, None, criteria, 10, cv.KMEANS_RANDOM_CENTERS)\n",
    "\n",
    "    # Calculate the average pixel value for each cluster\n",
    "    average_colors = np.uint8(centers)\n",
    "\n",
    "    # Find the index of the cluster with the lower average pixel value\n",
    "    cluster_index = np.argmin(average_colors)\n",
    "\n",
    "    # Convert the label image to 8-bit and reshape it to the original image shape\n",
    "    labels = labels.reshape(image.shape[:2]).astype(np.uint8)\n",
    "\n",
    "    white_area = np.sum(labels == 1)\n",
    "\n",
    "    # Convert the label image to 8-bit and reshape it to the original image shape\n",
    "    labels = labels.reshape(image.shape[:2]).astype(np.uint8)\n",
    "\n",
    "    # Invert the segmentation mask if the white area is larger than the segmented part\n",
    "    if white_area > (labels.size - white_area):\n",
    "        labels = 1 - labels\n",
    "        \n",
    "    # Segment the image based on the labels\n",
    "    segmented_image = np.where(labels == 1, 255, 0).astype(np.uint8)\n",
    "\n",
    "    return segmented_image\n",
    "\n",
    "def spot_cleanup(image):\n",
    "    # Convert the image to grayscale\n",
    "    gray = cv.cvtColor(image, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Perform adaptive thresholding to obtain a binary image\n",
    "    _, binary = cv.threshold(gray, 0, 255, cv.THRESH_BINARY_INV + cv.THRESH_OTSU)\n",
    "\n",
    "    # Perform morphological operations to clean the spots in the background\n",
    "    kernel_background = cv.getStructuringElement(cv.MORPH_RECT, (3, 3))\n",
    "    cleaned_background = cv.morphologyEx(binary, cv.MORPH_OPEN, kernel_background, iterations=2)\n",
    "\n",
    "    # Perform morphological operations to close the spots in the foreground\n",
    "    kernel_foreground = cv.getStructuringElement(cv.MORPH_RECT, (5, 5))\n",
    "    closed_foreground = cv.morphologyEx(cleaned_background, cv.MORPH_CLOSE, kernel_foreground, iterations=2)\n",
    "\n",
    "    # Invert the binary image to obtain the final mask\n",
    "    mask = cv.bitwise_not(closed_foreground)\n",
    "\n",
    "    # Apply the mask to the original image\n",
    "    segmented_image = cv.bitwise_and(image, image, mask=mask)\n",
    "\n",
    "    return segmented_image\n",
    "\n",
    "for i, path in enumerate(DATA_DIR):\n",
    "    if i == grid**2: break\n",
    "        \n",
    "    ax = plt.subplot(grid, grid, i + 1)\n",
    "    image = read_image(path)\n",
    "    mask = kmeans_segmentation(image)\n",
    "    mask = spot_cleanup(mask)\n",
    "    masked_image = cv.bitwise_and(image, image, mask=mask)\n",
    "    print(masked_image.shape)\n",
    "    # masked_image = spot_cleanup(masked_image)\n",
    "    display_image(masked_image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd39e2c-a6f9-488a-8f06-9f2a5abade19",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
